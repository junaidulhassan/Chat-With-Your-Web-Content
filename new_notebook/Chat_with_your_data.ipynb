{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":21394,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":17716}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T11:39:00.098346Z","iopub.execute_input":"2024-05-02T11:39:00.098695Z","iopub.status.idle":"2024-05-02T11:39:00.483400Z","shell.execute_reply.started":"2024-05-02T11:39:00.098666Z","shell.execute_reply":"2024-05-02T11:39:00.482344Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/mistral-7b-instruct/gguf/mistral-7b-instructv0.1/1/mistral-7b-instruct-v0.1.Q8_0.gguf\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install langchain llama-cpp-python ","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:12.532551Z","iopub.execute_input":"2024-05-02T11:42:12.533489Z","iopub.status.idle":"2024-05-02T11:42:12.537017Z","shell.execute_reply.started":"2024-05-02T11:42:12.533457Z","shell.execute_reply":"2024-05-02T11:42:12.536123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#!pip install sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:15.091302Z","iopub.execute_input":"2024-05-02T11:42:15.091682Z","iopub.status.idle":"2024-05-02T11:42:15.096361Z","shell.execute_reply.started":"2024-05-02T11:42:15.091644Z","shell.execute_reply":"2024-05-02T11:42:15.095376Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#!pip install chromadb","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:17.470141Z","iopub.execute_input":"2024-05-02T11:42:17.471063Z","iopub.status.idle":"2024-05-02T11:42:17.475103Z","shell.execute_reply.started":"2024-05-02T11:42:17.471022Z","shell.execute_reply":"2024-05-02T11:42:17.474214Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Import LLM model","metadata":{}},{"cell_type":"code","source":"# import packages from langchains for llm\nfrom langchain.llms import LlamaCpp\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.callbacks.manager import CallbackManager\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.embeddings import HuggingFaceEmbeddings","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:01.892881Z","iopub.execute_input":"2024-05-02T11:42:01.893262Z","iopub.status.idle":"2024-05-02T11:42:02.652461Z","shell.execute_reply.started":"2024-05-02T11:42:01.893228Z","shell.execute_reply":"2024-05-02T11:42:02.651703Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model_path = '/kaggle/input/mistral-7b-instruct/gguf/mistral-7b-instructv0.1/1/mistral-7b-instruct-v0.1.Q8_0.gguf'","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:21.401673Z","iopub.execute_input":"2024-05-02T11:42:21.402292Z","iopub.status.idle":"2024-05-02T11:42:21.406704Z","shell.execute_reply.started":"2024-05-02T11:42:21.402259Z","shell.execute_reply":"2024-05-02T11:42:21.405693Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"callbackManager = CallbackManager([StreamingStdOutCallbackHandler()])","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:21.582763Z","iopub.execute_input":"2024-05-02T11:42:21.583118Z","iopub.status.idle":"2024-05-02T11:42:21.587416Z","shell.execute_reply.started":"2024-05-02T11:42:21.583091Z","shell.execute_reply":"2024-05-02T11:42:21.586467Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"n_gpu_layers = 2  # Metal set to 1 is enough.\nn_batch = 512  \n\n# Make sure the model path is correct for your system!\nllm = LlamaCpp(\n    model_path=model_path,\n    n_gpu_layers=n_gpu_layers,\n    n_batch=n_batch,\n    n_ctx=2048,\n    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n    verbose=False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:42:21.752572Z","iopub.execute_input":"2024-05-02T11:42:21.753280Z","iopub.status.idle":"2024-05-02T11:43:21.525019Z","shell.execute_reply.started":"2024-05-02T11:42:21.753246Z","shell.execute_reply":"2024-05-02T11:43:21.524223Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Scrap Data from Website","metadata":{}},{"cell_type":"code","source":"# import python packages to scrap data from sites\n\nfrom langchain.document_loaders import WebBaseLoader\nfrom langchain.document_loaders import PyPDFLoader","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:21.526557Z","iopub.execute_input":"2024-05-02T11:43:21.527042Z","iopub.status.idle":"2024-05-02T11:43:21.681819Z","shell.execute_reply.started":"2024-05-02T11:43:21.526995Z","shell.execute_reply":"2024-05-02T11:43:21.681036Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"web_path = 'https://python.langchain.com/docs/use_cases/query_analysis/'","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:21.682870Z","iopub.execute_input":"2024-05-02T11:43:21.683261Z","iopub.status.idle":"2024-05-02T11:43:21.687778Z","shell.execute_reply.started":"2024-05-02T11:43:21.683236Z","shell.execute_reply":"2024-05-02T11:43:21.686711Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# now load the document\n\nloader = WebBaseLoader(\n    web_path = web_path,\n    header_template = None,\n    verify_ssl = True,\n    proxies = None,\n    continue_on_failure = False,\n    requests_per_second = 2,\n    default_parser = 'html.parser'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:21.689822Z","iopub.execute_input":"2024-05-02T11:43:21.690123Z","iopub.status.idle":"2024-05-02T11:43:21.699210Z","shell.execute_reply.started":"2024-05-02T11:43:21.690098Z","shell.execute_reply":"2024-05-02T11:43:21.698484Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"docs = loader.load()\ntxt_data = docs[0].page_content","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:21.700227Z","iopub.execute_input":"2024-05-02T11:43:21.700561Z","iopub.status.idle":"2024-05-02T11:43:22.112776Z","shell.execute_reply.started":"2024-05-02T11:43:21.700536Z","shell.execute_reply":"2024-05-02T11:43:22.112030Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"len(txt_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.113851Z","iopub.execute_input":"2024-05-02T11:43:22.114148Z","iopub.status.idle":"2024-05-02T11:43:22.120711Z","shell.execute_reply.started":"2024-05-02T11:43:22.114123Z","shell.execute_reply":"2024-05-02T11:43:22.119807Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"5570"},"metadata":{}}]},{"cell_type":"code","source":"txt_data[0:500]","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.121890Z","iopub.execute_input":"2024-05-02T11:43:22.122160Z","iopub.status.idle":"2024-05-02T11:43:22.131503Z","shell.execute_reply.started":"2024-05-02T11:43:22.122129Z","shell.execute_reply":"2024-05-02T11:43:22.130636Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'\\n\\n\\n\\n\\nQuery analysis | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\n\\nSkip to main contentComponentsIntegrationsGuidesAPI ReferenceMorePeopleVersioningContributingTemplatesCookbooksTutorialsYouTubeü¶úÔ∏èüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docsüí¨SearchGet startedIntroductionQuickstartInstallationUse casesQ&A with RAGExtracting structured outputChatbotsTool use and agentsQuery analysisQuickstarthow_toQuery analysistechniquesQ&A over SQL + CSVMoreExpression LanguageGet startedRu'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text Splitter","metadata":{}},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.text_splitter import CharacterTextSplitter","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.132526Z","iopub.execute_input":"2024-05-02T11:43:22.132774Z","iopub.status.idle":"2024-05-02T11:43:22.147525Z","shell.execute_reply.started":"2024-05-02T11:43:22.132753Z","shell.execute_reply":"2024-05-02T11:43:22.146480Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# now define the chunks and overlap\n\nchunks_size = 500\nchunks_overlap = 40\n\nrec_splitter = RecursiveCharacterTextSplitter(\n    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n    chunk_size=chunks_size,\n    chunk_overlap=chunks_overlap,\n    is_separator_regex=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.148721Z","iopub.execute_input":"2024-05-02T11:43:22.149552Z","iopub.status.idle":"2024-05-02T11:43:22.158083Z","shell.execute_reply.started":"2024-05-02T11:43:22.149513Z","shell.execute_reply":"2024-05-02T11:43:22.157141Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"rec_splitter.split_text(txt_data[0:1000])","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.162005Z","iopub.execute_input":"2024-05-02T11:43:22.162304Z","iopub.status.idle":"2024-05-02T11:43:22.170939Z","shell.execute_reply.started":"2024-05-02T11:43:22.162280Z","shell.execute_reply":"2024-05-02T11:43:22.170125Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['Query analysis | ü¶úÔ∏èüîó LangChain',\n 'Skip to main contentComponentsIntegrationsGuidesAPI ReferenceMorePeopleVersioningContributingTemplatesCookbooksTutorialsYouTubeü¶úÔ∏èüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docsüí¨SearchGet startedIntroductionQuickstartInstallationUse casesQ&A with RAGExtracting structured outputChatbotsTool use and agentsQuery analysisQuickstarthow_toQuery analysistechniquesQ&A over SQL + CSVMoreExpression LanguageGet startedRunnable interfacePrimitivesAdvantages of',\n 'interfacePrimitivesAdvantages of LCELStreamingAdd message history (memory)MoreEcosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏èLangGraphü¶úÔ∏èüèì LangServeSecurityUse casesQuery analysisOn this pageQuery analysis‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of',\n 'Retrieval Augmented Generation. The simplest way to do this involves\\npassing the user question directly to a retriever. In order to improve\\nperformance, you can also ‚Äúoptimize‚Äù the query in some way using query\\nanalysis. This is traditionally d']"},"metadata":{}}]},{"cell_type":"code","source":"# now try the Simple charater splitter\n\nsplitter = CharacterTextSplitter(\n    separator='\\n',\n    chunk_size=chunks_size,\n    chunk_overlap = chunks_overlap\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.171963Z","iopub.execute_input":"2024-05-02T11:43:22.172212Z","iopub.status.idle":"2024-05-02T11:43:22.180771Z","shell.execute_reply.started":"2024-05-02T11:43:22.172190Z","shell.execute_reply":"2024-05-02T11:43:22.179680Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"splitter.split_text(txt_data[0: 1500])","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.181946Z","iopub.execute_input":"2024-05-02T11:43:22.182515Z","iopub.status.idle":"2024-05-02T11:43:22.192851Z","shell.execute_reply.started":"2024-05-02T11:43:22.182484Z","shell.execute_reply":"2024-05-02T11:43:22.191991Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['Query analysis | ü¶úÔ∏èüîó LangChain',\n 'Skip to main contentComponentsIntegrationsGuidesAPI ReferenceMorePeopleVersioningContributingTemplatesCookbooksTutorialsYouTubeü¶úÔ∏èüîóLangSmithLangSmith DocsLangServe GitHubTemplates GitHubTemplates HubLangChain HubJS/TS Docsüí¨SearchGet startedIntroductionQuickstartInstallationUse casesQ&A with RAGExtracting structured outputChatbotsTool use and agentsQuery analysisQuickstarthow_toQuery analysistechniquesQ&A over SQL + CSVMoreExpression LanguageGet startedRunnable interfacePrimitivesAdvantages of LCELStreamingAdd message history (memory)MoreEcosystemü¶úüõ†Ô∏è LangSmithü¶úüï∏Ô∏èLangGraphü¶úÔ∏èüèì LangServeSecurityUse casesQuery analysisOn this pageQuery analysis‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of',\n 'Retrieval Augmented Generation. The simplest way to do this involves\\npassing the user question directly to a retriever. In order to improve\\nperformance, you can also ‚Äúoptimize‚Äù the query in some way using query\\nanalysis. This is traditionally done by rule-based techniques, but with\\nthe rise of LLMs it is becoming more popular and more feasible to use an\\nLLM for this. Specifically, this involves passing the raw question (or\\nlist of messages) into an LLM and returning one or more optimized',\n 'queries, which typically contain a string and optionally other\\nstructured information.Problems Solved\\u200bQuery analysis helps to optimize the search query to send to the\\nretriever. This can be the case when:The retriever supports searches and filters aga']"},"metadata":{}}]},{"cell_type":"code","source":"split = rec_splitter.split_documents(\n    docs\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.194106Z","iopub.execute_input":"2024-05-02T11:43:22.194969Z","iopub.status.idle":"2024-05-02T11:43:22.202020Z","shell.execute_reply.started":"2024-05-02T11:43:22.194936Z","shell.execute_reply":"2024-05-02T11:43:22.201226Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"embedding = HuggingFaceEmbeddings(\n    model_name='all-MiniLM-L6-v2'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:22.203045Z","iopub.execute_input":"2024-05-02T11:43:22.203317Z","iopub.status.idle":"2024-05-02T11:43:33.403256Z","shell.execute_reply.started":"2024-05-02T11:43:22.203294Z","shell.execute_reply":"2024-05-02T11:43:33.402430Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6510499a9834b0b87d556db2d1900ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac81505a570e47b2903e692154658464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91e77b83427b46368692a0db319def17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"144dfa72f30547f5886e595b86222161"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32cf3a79065742028fa4a44c347f76c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad7bd3691c54652a2ad574206d0b822"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"998494c85cc74beca2a7b0fcef74e36f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"820aa600e41b49ecab6fe1f1bb827b25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7af45de5b1f4ece8aaf012d6c8a333e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb463eb117e748e1b335059e6c5f1caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bee2fb1cefc4ba5ab8c5ec9d203dfa1"}},"metadata":{}}]},{"cell_type":"code","source":"t1= \"I love dogs\"\nt2 = \"I love cats\"\nt3 = \"Study is very hard\"","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:33.404464Z","iopub.execute_input":"2024-05-02T11:43:33.405029Z","iopub.status.idle":"2024-05-02T11:43:33.409600Z","shell.execute_reply.started":"2024-05-02T11:43:33.404999Z","shell.execute_reply":"2024-05-02T11:43:33.408651Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"embd1 = embedding.embed_query(t1)\nembd2 = embedding.embed_query(t2)\nembd3 = embedding.embed_query(t3)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:33.411175Z","iopub.execute_input":"2024-05-02T11:43:33.411813Z","iopub.status.idle":"2024-05-02T11:43:34.554428Z","shell.execute_reply.started":"2024-05-02T11:43:33.411778Z","shell.execute_reply":"2024-05-02T11:43:34.553627Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"np.dot(embd1,embd2), np.dot(embd2,embd3)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:34.555513Z","iopub.execute_input":"2024-05-02T11:43:34.555800Z","iopub.status.idle":"2024-05-02T11:43:34.562348Z","shell.execute_reply.started":"2024-05-02T11:43:34.555775Z","shell.execute_reply":"2024-05-02T11:43:34.561416Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(0.7720984757242813, 0.06933481201584218)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Add Vector Databases","metadata":{}},{"cell_type":"code","source":"from langchain.vectorstores import Chroma\nfrom langchain.vectorstores import pinecone","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:34.563528Z","iopub.execute_input":"2024-05-02T11:43:34.563823Z","iopub.status.idle":"2024-05-02T11:43:34.575421Z","shell.execute_reply.started":"2024-05-02T11:43:34.563799Z","shell.execute_reply":"2024-05-02T11:43:34.574659Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"db = Chroma.from_documents(\n    documents= split,\n    embedding=embedding,\n    collection_name='langchain',\n    persist_directory='docs/chroma/'\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:34.576645Z","iopub.execute_input":"2024-05-02T11:43:34.577516Z","iopub.status.idle":"2024-05-02T11:43:36.301078Z","shell.execute_reply.started":"2024-05-02T11:43:34.577491Z","shell.execute_reply":"2024-05-02T11:43:36.300111Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"query = 'word embedding'","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:36.302346Z","iopub.execute_input":"2024-05-02T11:43:36.303049Z","iopub.status.idle":"2024-05-02T11:43:36.307103Z","shell.execute_reply.started":"2024-05-02T11:43:36.303014Z","shell.execute_reply":"2024-05-02T11:43:36.306207Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"db.similarity_search(\n    query=query,\n    k=3\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:43:36.308428Z","iopub.execute_input":"2024-05-02T11:43:36.308771Z","iopub.status.idle":"2024-05-02T11:43:36.337670Z","shell.execute_reply.started":"2024-05-02T11:43:36.308739Z","shell.execute_reply":"2024-05-02T11:43:36.336852Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='embeddings may not be very similar to those of the relevant\\ndocuments. Instead it might help to have the model generate a\\nhypothetical relevant document, and then use that to perform\\nsimilarity search.Query routing:\\nIf we have multiple indexes and only a subset are useful for any\\ngiven user input, we can route the input to only retrieve results\\nfrom the relevant ones.Step back\\nprompting:\\nSometimes search quality and model generations can be tripped up by', metadata={'description': '‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of', 'language': 'en', 'source': 'https://python.langchain.com/docs/use_cases/query_analysis/', 'title': 'Query analysis | ü¶úÔ∏èüîó LangChain'}),\n Document(page_content='decompose the input into separate queries that will each be executed\\nindependently.Query\\nexpansion: If\\nan index is sensitive to query phrasing, we can generate multiple\\nparaphrased versions of the user question to increase our chances of\\nretrieving a relevant result.Hypothetical document embedding\\n(HyDE): If we‚Äôre\\nworking with a similarity search-based index, like a vector store,\\nthen searching on raw questions may not work well because their', metadata={'description': '‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of', 'language': 'en', 'source': 'https://python.langchain.com/docs/use_cases/query_analysis/', 'title': 'Query analysis | ü¶úÔ∏èüîó LangChain'}),\n Document(page_content='Query analysis | ü¶úÔ∏èüîó LangChain', metadata={'description': '‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of', 'language': 'en', 'source': 'https://python.langchain.com/docs/use_cases/query_analysis/', 'title': 'Query analysis | ü¶úÔ∏èüîó LangChain'})]"},"metadata":{}}]},{"cell_type":"code","source":"# using MMR\n\nmmr_docs = db.max_marginal_relevance_search(\n    query=query,\n    k=2,\n    fetch_k=2\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:46:31.067619Z","iopub.execute_input":"2024-05-02T11:46:31.068317Z","iopub.status.idle":"2024-05-02T11:46:31.090671Z","shell.execute_reply.started":"2024-05-02T11:46:31.068282Z","shell.execute_reply":"2024-05-02T11:46:31.089745Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"mmr_docs","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:46:33.075427Z","iopub.execute_input":"2024-05-02T11:46:33.076265Z","iopub.status.idle":"2024-05-02T11:46:33.082094Z","shell.execute_reply.started":"2024-05-02T11:46:33.076232Z","shell.execute_reply":"2024-05-02T11:46:33.081224Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[Document(page_content='embeddings may not be very similar to those of the relevant\\ndocuments. Instead it might help to have the model generate a\\nhypothetical relevant document, and then use that to perform\\nsimilarity search.Query routing:\\nIf we have multiple indexes and only a subset are useful for any\\ngiven user input, we can route the input to only retrieve results\\nfrom the relevant ones.Step back\\nprompting:\\nSometimes search quality and model generations can be tripped up by', metadata={'description': '‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of', 'language': 'en', 'source': 'https://python.langchain.com/docs/use_cases/query_analysis/', 'title': 'Query analysis | ü¶úÔ∏èüîó LangChain'}),\n Document(page_content='decompose the input into separate queries that will each be executed\\nindependently.Query\\nexpansion: If\\nan index is sensitive to query phrasing, we can generate multiple\\nparaphrased versions of the user question to increase our chances of\\nretrieving a relevant result.Hypothetical document embedding\\n(HyDE): If we‚Äôre\\nworking with a similarity search-based index, like a vector store,\\nthen searching on raw questions may not work well because their', metadata={'description': '‚ÄúSearch‚Äù powers many use cases - including the ‚Äúretrieval‚Äù part of', 'language': 'en', 'source': 'https://python.langchain.com/docs/use_cases/query_analysis/', 'title': 'Query analysis | ü¶úÔ∏èüîó LangChain'})]"},"metadata":{}}]},{"cell_type":"code","source":"from langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:52:16.512432Z","iopub.execute_input":"2024-05-02T11:52:16.512789Z","iopub.status.idle":"2024-05-02T11:52:16.517396Z","shell.execute_reply.started":"2024-05-02T11:52:16.512760Z","shell.execute_reply":"2024-05-02T11:52:16.516385Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"meta_data_field_info = [\n    AttributeInfo(\n        name='source',\n        description='Text chunks should be one of `/docs/use_cases/query_analysis/`',\n        type='string'\n    ),\n    AttributeInfo(\n        name='source',\n        description='The heading from contexts',\n        type='string'\n    )\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-02T11:56:27.026443Z","iopub.execute_input":"2024-05-02T11:56:27.027039Z","iopub.status.idle":"2024-05-02T11:56:27.031661Z","shell.execute_reply.started":"2024-05-02T11:56:27.027006Z","shell.execute_reply":"2024-05-02T11:56:27.030773Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"!pip install lark","metadata":{"execution":{"iopub.status.busy":"2024-05-02T12:02:22.419061Z","iopub.execute_input":"2024-05-02T12:02:22.419437Z","iopub.status.idle":"2024-05-02T12:02:35.329118Z","shell.execute_reply.started":"2024-05-02T12:02:22.419406Z","shell.execute_reply":"2024-05-02T12:02:35.327981Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: lark in /opt/conda/lib/python3.10/site-packages (1.1.9)\n","output_type":"stream"}]},{"cell_type":"code","source":"import lark","metadata":{"execution":{"iopub.status.busy":"2024-05-02T12:02:51.975017Z","iopub.execute_input":"2024-05-02T12:02:51.975649Z","iopub.status.idle":"2024-05-02T12:02:51.979892Z","shell.execute_reply.started":"2024-05-02T12:02:51.975619Z","shell.execute_reply":"2024-05-02T12:02:51.978972Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"docs_content_disc = 'Langchain RAG'\n\nret = SelfQueryRetriever.from_llm(\n    llm,\n    db,\n    docs_content_disc,\n    meta_data_field_info,\n    verbose=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T12:02:54.179685Z","iopub.execute_input":"2024-05-02T12:02:54.180288Z","iopub.status.idle":"2024-05-02T12:02:54.284589Z","shell.execute_reply.started":"2024-05-02T12:02:54.180256Z","shell.execute_reply":"2024-05-02T12:02:54.283280Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m docs_content_disc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLangchain RAG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mSelfQueryRetriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocs_content_disc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_data_field_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/retrievers/self_query/base.py:277\u001b[0m, in \u001b[0;36mSelfQueryRetriever.from_llm\u001b[0;34m(cls, llm, vectorstore, document_contents, metadata_field_info, structured_query_translator, chain_kwargs, enable_limit, use_original_query, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed_operators\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m chain_kwargs\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m structured_query_translator\u001b[38;5;241m.\u001b[39mallowed_operators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    273\u001b[0m ):\n\u001b[1;32m    274\u001b[0m     chain_kwargs[\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallowed_operators\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     ] \u001b[38;5;241m=\u001b[39m structured_query_translator\u001b[38;5;241m.\u001b[39mallowed_operators\n\u001b[0;32m--> 277\u001b[0m query_constructor \u001b[38;5;241m=\u001b[39m \u001b[43mload_query_constructor_runnable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocument_contents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_field_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mchain_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m query_constructor \u001b[38;5;241m=\u001b[39m query_constructor\u001b[38;5;241m.\u001b[39mwith_config(\n\u001b[1;32m    285\u001b[0m     run_name\u001b[38;5;241m=\u001b[39mQUERY_CONSTRUCTOR_RUN_NAME\n\u001b[1;32m    286\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     query_constructor\u001b[38;5;241m=\u001b[39mquery_constructor,\n\u001b[1;32m    289\u001b[0m     vectorstore\u001b[38;5;241m=\u001b[39mvectorstore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:361\u001b[0m, in \u001b[0;36mload_query_constructor_runnable\u001b[0;34m(llm, document_contents, attribute_info, examples, allowed_comparators, allowed_operators, enable_limit, schema_prompt, fix_invalid, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ainfo \u001b[38;5;129;01min\u001b[39;00m attribute_info:\n\u001b[1;32m    358\u001b[0m     allowed_attributes\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    359\u001b[0m         ainfo\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ainfo, AttributeInfo) \u001b[38;5;28;01melse\u001b[39;00m ainfo[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    360\u001b[0m     )\n\u001b[0;32m--> 361\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m \u001b[43mStructuredQueryOutputParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_components\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_comparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_comparators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_operators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_operators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfix_invalid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_invalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prompt \u001b[38;5;241m|\u001b[39m llm \u001b[38;5;241m|\u001b[39m output_parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:99\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.from_components\u001b[0;34m(cls, allowed_comparators, allowed_operators, allowed_attributes, fix_invalid)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m fixed\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     ast_parse \u001b[38;5;241m=\u001b[39m \u001b[43mget_parser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_comparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_comparators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_operators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_operators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparse\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(ast_parse\u001b[38;5;241m=\u001b[39mast_parse)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/query_constructor/parser.py:173\u001b[0m, in \u001b[0;36mget_parser\u001b[0;34m(allowed_comparators, allowed_operators, allowed_attributes)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# QueryTransformer is None when Lark cannot be imported.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m QueryTransformer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot import lark, please install it with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install lark\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m transformer \u001b[38;5;241m=\u001b[39m QueryTransformer(\n\u001b[1;32m    177\u001b[0m     allowed_comparators\u001b[38;5;241m=\u001b[39mallowed_comparators,\n\u001b[1;32m    178\u001b[0m     allowed_operators\u001b[38;5;241m=\u001b[39mallowed_operators,\n\u001b[1;32m    179\u001b[0m     allowed_attributes\u001b[38;5;241m=\u001b[39mallowed_attributes,\n\u001b[1;32m    180\u001b[0m )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Lark(GRAMMAR, parser\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlalr\u001b[39m\u001b[38;5;124m\"\u001b[39m, transformer\u001b[38;5;241m=\u001b[39mtransformer, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprogram\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mImportError\u001b[0m: Cannot import lark, please install it with 'pip install lark'."],"ename":"ImportError","evalue":"Cannot import lark, please install it with 'pip install lark'.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}